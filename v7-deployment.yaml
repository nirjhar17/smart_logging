apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-troubleshooter-v8
  namespace: ai-troubleshooter-v8
  labels:
    app: ai-troubleshooter-v8
    version: v8
    component: multi-agent-rag
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ai-troubleshooter-v8
  template:
    metadata:
      labels:
        app: ai-troubleshooter-v8
        version: v8
        component: multi-agent-rag
    spec:
      serviceAccountName: ai-troubleshooter-v8-sa
      containers:
      - name: streamlit-app
        image: registry.access.redhat.com/ubi9/python-311:latest
        command: ["/bin/bash"]
        args:
          - -c
          - |
            echo "ðŸš€ Starting AI Troubleshooter v7 - Multi-Agent RAG"
            
            # Install oc client to user local bin
            mkdir -p ~/bin
            curl -L -o /tmp/oc.tar.gz https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-client-linux.tar.gz
            tar -xzf /tmp/oc.tar.gz -C ~/bin/
            export PATH=~/bin:$PATH
            
            # Install Python dependencies
            pip install --no-cache-dir fire>=0.5.0 langgraph>=0.2.0 langchain==0.2.16 langchain-core==0.2.38 langchain-community==0.2.16 llama-stack-client>=0.0.53 rank-bm25>=0.2.2 faiss-cpu>=1.9.0 pymilvus>=2.5.0 streamlit>=1.28.0 pandas>=2.0.0 numpy>=1.23.0 requests>=2.31.0 httpx>=0.28.0 python-dotenv>=1.0.0 pydantic>=2.0.0 typing-extensions>=4.12.0
            
            # Copy application code
            cp /app-config/*.py /tmp/
            
            # Create .env file
            cat > /tmp/.env << EOF
            LLAMA_STACK_URL=${LLAMA_STACK_URL}
            LLAMA_STACK_MODEL=${LLAMA_STACK_MODEL}
            EMBEDDING_MODEL=${EMBEDDING_MODEL}
            EMBEDDING_DIMENSION=${EMBEDDING_DIMENSION}
            VECTOR_DB_ID=${VECTOR_DB_ID}
            BGE_RERANKER_URL=${BGE_RERANKER_URL}
            MAX_ITERATIONS=${MAX_ITERATIONS}
            OCP_MCP_URL=${OCP_MCP_URL}
            EOF
            
            # Start the application
            cd /tmp
            echo "ðŸŽ¯ Starting AI Troubleshooter v8 (Chat Interface) on port 8501"
            python -m streamlit run app.py --server.port=8501 --server.address=0.0.0.0 --server.headless=true
        env:
        - name: LLAMA_STACK_URL
          value: "http://llamastack-custom-distribution-service.model.svc.cluster.local:8321"
        - name: LLAMA_STACK_MODEL
          value: "llama-32-3b-instruct"
        - name: EMBEDDING_MODEL
          value: "granite-embedding-125m"
        - name: EMBEDDING_DIMENSION
          value: "768"
        - name: VECTOR_DB_ID
          value: "openshift-logs-v7"
        - name: BGE_RERANKER_URL
          value: "https://bge-reranker-model.apps.rosa.loki123.orwi.p3.openshiftapps.com"
        - name: MAX_ITERATIONS
          value: "3"
        - name: OCP_MCP_URL
          value: "http://ocp-mcp-server.model.svc.cluster.local:8000/sse"
        ports:
        - containerPort: 8501
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /
            port: 8501
          initialDelaySeconds: 120
          periodSeconds: 30
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 8501
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
        resources:
          limits:
            cpu: "1"
            memory: 2Gi
          requests:
            cpu: 250m
            memory: 512Mi
        volumeMounts:
        - name: app-config
          mountPath: /app-config
      volumes:
      - name: app-config
        configMap:
          name: ai-troubleshooter-v8-code
---
apiVersion: v1
kind: Service
metadata:
  name: ai-troubleshooter-v8-service
  namespace: ai-troubleshooter-v8
  labels:
    app: ai-troubleshooter-v8
spec:
  selector:
    app: ai-troubleshooter-v8
  ports:
  - name: http
    port: 8501
    targetPort: 8501
    protocol: TCP
  type: ClusterIP
---
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: ai-troubleshooter-v8
  namespace: ai-troubleshooter-v8
  labels:
    app: ai-troubleshooter-v8
spec:
  to:
    kind: Service
    name: ai-troubleshooter-v8-service
  port:
    targetPort: http
  tls:
    termination: edge
    insecureEdgeTerminationPolicy: Redirect
  wildcardPolicy: None

