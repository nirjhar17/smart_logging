# Smart Logging - Multi-Agent RAG for OpenShift

**Multi-agent self-corrective RAG system for OpenShift/Kubernetes log analysis**

[![Status](https://img.shields.io/badge/status-production--ready-green)]()
[![Detection Rate](https://img.shields.io/badge/detection--rate-100%25-brightgreen)]()
[![License](https://img.shields.io/badge/license-Apache%202.0-blue)]()

---

## ğŸ¯ Overview

Smart Logging analyzes OpenShift/Kubernetes logs using a multi-agent AI system inspired by [NVIDIA's architecture](https://developer.nvidia.com/blog/build-a-log-analysis-multi-agent-self-corrective-rag-system-with-nvidia-nemotron/). It automatically identifies issues, root causes, and provides actionable solutions.

### Key Features

- âœ… **100% Detection Rate** - Identifies all pod issues including missing ConfigMaps and Secrets
- ğŸ” **Hybrid Retrieval** - Combines BM25 (lexical) + FAISS (semantic) with Reciprocal Rank Fusion
- ğŸ¯ **BGE Reranker** - Refines results using BGE Reranker v2-m3
- ğŸ”„ **Self-Corrective** - Iterative query transformation (up to 3 iterations)
- ğŸ¤– **5 Specialized Agents** - Retrieve, Rerank, Grade, Generate, Transform
- ğŸš€ **Fast** - 5-10 second response time

---

## ğŸ“Š Performance

| Metric | Value |
|--------|-------|
| Issue Detection | 100% |
| Response Time | 5-10 seconds |
| Chunks per Pod | 3-5 |
| Self-Correction Iterations | 0-3 (avg 0.5) |

---

## ğŸ—ï¸ Architecture

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent 1: Retrieve            â”‚
â”‚ â€¢ Fetch logs (oc describe)  â”‚
â”‚ â€¢ Hybrid: BM25 + FAISS      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent 2: Rerank              â”‚
â”‚ â€¢ BGE Reranker v2-m3        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent 3: Grade Documents     â”‚
â”‚ â€¢ Inclusive philosophy      â”‚
â”‚ â€¢ Full content evaluation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent 4: Generate Answer     â”‚
â”‚ â€¢ Llama 3.2 3B Instruct     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Decision: Answer Quality?    â”‚
â”‚ Good â†’ Return               â”‚
â”‚ Poor â†’ Agent 5: Transform   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- OpenShift 4.x or Kubernetes 1.20+
- Llama Stack service with:
  - LLM: `llama-32-3b-instruct`
  - Embeddings: `granite-embedding-125m`
- BGE Reranker v2-m3 service
- `oc` CLI installed

### Deploy in 5 Minutes

```bash
# 1. Clone repository
git clone https://github.com/nirjhar17/smart_logging.git
cd smart_logging

# 2. Create namespace
oc new-project smart-logging

# 3. Deploy RBAC
oc apply -f v8-rbac.yaml

# 4. Create ConfigMap with code
oc create configmap smart-logging-code \
  --from-file=v7_graph_nodes.py \
  --from-file=v7_graph_edges.py \
  --from-file=v7_main_graph.py \
  --from-file=v7_state_schema.py \
  --from-file=v7_bge_reranker.py \
  --from-file=k8s_hybrid_retriever.py \
  --from-file=k8s_log_fetcher.py \
  --from-file=v8_streamlit_chat_app.py \
  --from-file=app.py=v8_streamlit_chat_app.py

# 5. Update environment variables in v7-deployment.yaml
# Set LLAMA_STACK_URL and BGE_RERANKER_URL

# 6. Deploy
oc apply -f v7-deployment.yaml

# 7. Get route URL
oc get route smart-logging
```

---

## âš™ï¸ Configuration

Edit environment variables in `v7-deployment.yaml`:

```yaml
env:
- name: LLAMA_STACK_URL
  value: "http://your-llama-stack:8321"
- name: BGE_RERANKER_URL
  value: "https://your-bge-reranker"
- name: LLAMA_STACK_MODEL
  value: "llama-32-3b-instruct"
- name: EMBEDDING_MODEL
  value: "granite-embedding-125m"
```

---

## ğŸ§ª Example Usage

### Healthy Pod
```
Query: What is the issue with pod nginx-xxx?
Answer: âœ… No issues detected. Pod is running normally.
```

### Missing Resources
```
Query: What is the issue with pod app-xxx?
Answer: 
ğŸš¨ ISSUE: Multiple missing resources
- Missing ConfigMap: app-config
- Missing Secret: app-secret

ğŸ”§ RESOLUTION:
oc create configmap app-config --from-literal=...
oc create secret generic app-secret --from-literal=...
```

---

## ğŸ”§ Technical Details

### Hybrid Retrieval
- **BM25**: Lexical/keyword matching
- **FAISS**: Semantic similarity (Granite 125M embeddings)
- **RRF**: Reciprocal Rank Fusion for combining results

### Chunking Strategy
- **Chunk Size**: 1,000 characters (optimized for BGE's 512 token limit)
- **Overlap**: 200 characters (20%)
- **Separators**: `\n\n`, `\n`, ` `

### Critical Fixes Applied

This version includes 3 critical fixes that improved detection from 50% to 100%:

1. **Full Document Grading** - Agent 3 sees complete content (no truncation)
2. **Inclusive Philosophy** - "Partial relevance = yes" (from NVIDIA)
3. **Optimized Chunk Size** - 1K chars (fits BGE's 512 token limit)

See [CRITICAL_FIXES_APPLIED.md](./CRITICAL_FIXES_APPLIED.md) for technical details.

---

## ğŸ“ Repository Structure

```
smart_logging/
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ CRITICAL_FIXES_APPLIED.md     # Technical fix details
â”‚
â”œâ”€â”€ Python Files (Agents & Logic)
â”‚   â”œâ”€â”€ v7_graph_nodes.py         # 5 agent implementations
â”‚   â”œâ”€â”€ v7_graph_edges.py         # Routing logic
â”‚   â”œâ”€â”€ v7_main_graph.py          # LangGraph workflow
â”‚   â”œâ”€â”€ v7_state_schema.py        # State management
â”‚   â”œâ”€â”€ k8s_hybrid_retriever.py   # Hybrid retrieval (NVIDIA-style)
â”‚   â”œâ”€â”€ v7_bge_reranker.py        # BGE reranker client
â”‚   â”œâ”€â”€ k8s_log_fetcher.py        # Log fetcher
â”‚   â””â”€â”€ v8_streamlit_chat_app.py  # Chat UI
â”‚
â””â”€â”€ Kubernetes Manifests
    â”œâ”€â”€ v7-deployment.yaml        # Main deployment
    â””â”€â”€ v8-rbac.yaml              # RBAC configuration
```

---

## ğŸ” Troubleshooting

### Pod Not Starting
```bash
# Check logs
oc logs deployment/smart-logging

# Common issues:
# 1. Llama Stack URL incorrect
# 2. BGE Reranker URL incorrect
# 3. RBAC not configured
```

### Detection Issues
```bash
# Verify chunk size
oc get configmap smart-logging-code -o yaml | grep chunk_size
# Should show: chunk_size=1000

# Check logs for retrieval
oc logs deployment/smart-logging | grep "Retrieved.*documents"
# Should show multiple documents (3-5+)
```

---

## ğŸ“ Inspiration

Based on [NVIDIA's Multi-Agent Log Analysis](https://developer.nvidia.com/blog/build-a-log-analysis-multi-agent-self-corrective-rag-system-with-nvidia-nemotron/) approach, adapted for OpenShift with self-hosted models.

### Key Adaptations
- NVIDIA NV-EmbedQA-1B â†’ Granite 125M
- NVIDIA Nemotron 49B â†’ Llama 3.2 3B
- NVIDIA NV-RerankQA-1B â†’ BGE Reranker v2-m3
- Generic logs â†’ OpenShift-specific
- NVIDIA AI Endpoints â†’ Llama Stack

---

## ğŸ“š Documentation

- **README.md** - This file (overview & quick start)
- **CRITICAL_FIXES_APPLIED.md** - Technical details of 3 critical fixes

---

## ğŸ¤ Contributing

Contributions welcome! Key areas:
- Agent prompt optimization
- Additional retrieval strategies
- Performance improvements
- New deployment targets

---

## ğŸ“ License

Apache 2.0 - Adapts concepts from NVIDIA's GenerativeAIExamples

---

## ğŸ”— Links

- **GitHub**: https://github.com/nirjhar17/smart_logging
- **NVIDIA Blog**: https://developer.nvidia.com/blog/build-a-log-analysis-multi-agent-self-corrective-rag-system-with-nvidia-nemotron/
- **NVIDIA Code**: https://github.com/NVIDIA/GenerativeAIExamples/tree/main/community/log_analysis_multi_agent_rag

---

**Built with â¤ï¸ for OpenShift Troubleshooting**
