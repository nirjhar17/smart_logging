apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "3"
  creationTimestamp: "2025-10-04T23:32:25Z"
  generation: 3
  name: llamastack-custom-distribution
  namespace: model
  ownerReferences:
  - apiVersion: llamastack.io/v1alpha1
    blockOwnerDeletion: true
    controller: true
    kind: LlamaStackDistribution
    name: llamastack-custom-distribution
    uid: 8fc2f441-fe04-4c53-b685-c398d977a928
  resourceVersion: "43310525"
  uid: b394a380-9ad5-47b6-82ff-95a3ab2b3693
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: llama-stack
      app.kubernetes.io/instance: llamastack-custom-distribution
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      annotations:
        instrumentation.opentelemetry.io/inject-python: opentelemetrycollector/auto-instrumentation
        instrumentation.opentelemetry.io/python-container-names: llama-stack
        kubectl.kubernetes.io/restartedAt: "2025-10-06T11:53:39+08:00"
      creationTimestamp: null
      labels:
        app: llama-stack
        app.kubernetes.io/instance: llamastack-custom-distribution
    spec:
      containers:
      - env:
        - name: HF_HOME
          value: /.llama
        - name: VLLM_URL
          valueFrom:
            secretKeyRef:
              key: VLLM_URL
              name: llama-stack-inference-model-secret
        - name: INFERENCE_MODEL
          valueFrom:
            secretKeyRef:
              key: INFERENCE_MODEL
              name: llama-stack-inference-model-secret
        - name: VLLM_TLS_VERIFY
          valueFrom:
            secretKeyRef:
              key: VLLM_TLS_VERIFY
              name: llama-stack-inference-model-secret
        - name: VLLM_API_TOKEN
          valueFrom:
            secretKeyRef:
              key: VLLM_API_TOKEN
              name: llama-stack-inference-model-secret
        - name: MILVUS_DB_PATH
          value: ~/.llama/milvus.db
        - name: FMS_ORCHESTRATOR_URL
          value: http://localhost:1234
        image: quay.io/opendatahub/llama-stack:odh
        imagePullPolicy: Always
        name: llama-stack
        ports:
        - containerPort: 8321
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /.llama
          name: lls-storage
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
      volumes:
      - name: lls-storage
        persistentVolumeClaim:
          claimName: llamastack-custom-distribution-pvc
status:
  availableReplicas: 1
  conditions:
  - lastTransitionTime: "2025-10-04T23:32:25Z"
    lastUpdateTime: "2025-10-06T03:55:45Z"
    message: ReplicaSet "llamastack-custom-distribution-549645b86d" has successfully
      progressed.
    reason: NewReplicaSetAvailable
    status: "True"
    type: Progressing
  - lastTransitionTime: "2025-10-09T12:59:02Z"
    lastUpdateTime: "2025-10-09T12:59:02Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: "True"
    type: Available
  observedGeneration: 3
  readyReplicas: 1
  replicas: 1
  updatedReplicas: 1
